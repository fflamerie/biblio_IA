@article{acut2025ChatGPT40,
  title = {``{{ChatGPT}} 4.0 {{Ghosted Us While Conducting Literature Search}}:'' {{Modeling}} the {{Chatbot}}'s {{Generated Non-Existent References Using Regression Analysis}}},
  shorttitle = {``{{ChatGPT}} 4.0 {{Ghosted Us While Conducting Literature Search}}},
  author = {Acut, Dharel P. and Malabago, Nolasco K. and Malicoban, Elesar V. and Galamiton, Narcisan S. and Garcia, Manuel B.},
  year = 2025,
  month = jan,
  journal = {Internet Reference Services Quarterly},
  volume = {29},
  number = {1},
  pages = {27--54},
  publisher = {Routledge},
  issn = {1087-5301},
  doi = {10.1080/10875301.2024.2426793},
  urldate = {2025-07-22},
  abstract = {The integration of AI technologies like ChatGPT has transformed academic research, yet substantial gaps exist in understanding the implications of AI-generated non-existent references in literature searches. While prior studies have predominantly focused on medical and geography fields using descriptive statistics, a systematic investigation into ChatGPT 4.0's effectiveness in generating accurate references within the realm of science and technology education remains unexplored, highlighting a significant dearth of research in this critical area. This study, therefore, investigates the reliability of AI-generated references in academic writing utilizing ChatGPT 4.0. Employing a non-experimental correlational design, the research examines the impact of prompt specificity on citation accuracy across various types of prompts, including general, specific, methodological, review, and interdisciplinary prompts. The findings indicate that specific, review, and interdisciplinary prompts correlate positively with accurate references, while general prompts frequently result in non-existent references. Visualizations, including a confusion matrix and precision-recall curve, illustrate the model's performance. Ultimately, the study underscores the necessity of well-structured prompts to enhance reference quality and cautions against AI-induced hallucinations that produce non-existent references, which can significantly undermine research credibility.},
  annotation = {Pinned\_Collections: library}
}

@article{andersen2025GenerativeArtificial,
  title = {Generative {{Artificial Intelligence}} ({{GenAI}}) in the Research Process -- {{A}} Survey of Researchers' Practices and Perceptions},
  author = {Andersen, Jens Peter and Degn, Lise and Fishberg, Rachel and Graversen, Ebbe K. and Horbach, Serge P. J. M. and Schmidt, Evanthia Kalpazidou and Schneider, Jesper W. and S{\o}rensen, Mads P.},
  year = 2025,
  month = jun,
  journal = {Technology in Society},
  volume = {81},
  pages = {102813},
  issn = {0160-791X},
  doi = {10.1016/j.techsoc.2025.102813},
  urldate = {2025-07-09},
  abstract = {This study explores the use of generative AI (GenAI) and research integrity assessments of use cases by researchers, including PhD students, at Danish universities. Conducted through a survey sent to all Danish researchers from January to February 2024, the study received 2534 responses and evaluated 32 GenAI use cases across five research phases: idea generation, research design, data collection, data analysis, and writing/reporting. Respondents reported on their own and colleagues' GenAI usage. They also assessed whether the practices in the use cases were considered good research practice. Through an explorative factor analysis, we identified three clusters of perception: "GenAI as a work horse", "GenAI as a language assistant only", and "GenAI as a research accelerator". The findings further show varied opinions on GenAI's research integrity implications. Language editing and data analysis were generally viewed positively, whereas experiment design and peer review tasks faced more criticism. Controversial areas included image creation/modification and synthetic data, with comments highlighting the need for critical and reflexive use of GenAI. Usage differed by main research area, with technical and quantitative sciences reporting slightly higher usage and more positive assessments. Junior researchers used GenAI more than senior colleagues, while no significant gender differences were observed. The study underscores the need for adaptable, discipline-specific guidelines for GenAI use in research, developed collaboratively with experts to align with diverse research practices and minimize ethical and practical misalignment.},
  annotation = {Pinned\_Collections: library}
}

@article{bhattacharyya2023HighRates,
  title = {High {{Rates}} of {{Fabricated}} and {{Inaccurate References}} in {{ChatGPT-Generated Medical Content}}},
  author = {Bhattacharyya, Mehul and Miller, Valerie M and Bhattacharyya, Debjani and Miller, Larry E},
  year = 2023,
  month = may,
  journal = {Cureus},
  volume = {15},
  number = {5},
  pages = {e39238},
  publisher = {{Springer Science and Business Media LLC}},
  issn = {2168-8184},
  doi = {10.7759/cureus.39238},
  urldate = {2025-07-21},
  langid = {english},
  annotation = {Pinned\_Collections: library}
}

@misc{bouchard2025FormerUsagers,
  title = {{Former les usagers \`a l'heure de ChatGPT : IA et comp\'etences informationnelles (formation de formateurs)}},
  shorttitle = {{Ressource - Former les usagers \`a l'heure de ChatGPT}},
  author = {Bouchard, Aline},
  year = 2025,
  urldate = {2025-12-04},
  langid = {french}
}

@misc{bouchard2025IARecherche,
  title = {{{IA}} et Recherche Documentaire : {{ChatGPT}} et Les Autres},
  author = {Bouchard, Aline},
  year = 2025,
  publisher = {Callisto Formation},
  urldate = {2025-12-03}
}

@misc{bouchard2025WorkInProgressIA,
  title = {''\#{{WorkInProgress}} : {{IA}} G\'en\'erative et Outils de Recherche de Litt\'erature Acad\'emique''},
  shorttitle = {''\#{{WorkInProgress}}},
  author = {Bouchard, Aline},
  year = 2025,
  month = feb,
  journal = {URFISTinfo},
  urldate = {2025-03-04},
  abstract = {La recherche d'informations et la revue de litt\'erature acad\'emique n'\'echappent pas \`a la r\'ecente vague d'intelligence artificielle g\'en\'erative, promesse d'assistance et de productivit\'e. Durant les deux ann\'ees \'ecoul\'ees, l'engouement autour de ChatGPT est venu mettre en lumi\`ere l'int\'egration de fonctionnalit\'es d'intelligence artificielle (IA) g\'en\'erative dans les outils de recherche. Port\'e d'une part par les progr\`es s\'emantiques des grands mod\`eles de langage (LLM), d'autre part par une diversification et de nouvelles capacit\'es des outils, le paysage de la recherche d'information a d\'ej\`a bien chang\'e, entre tchatbots, moteurs de recherche et outils de recherche bibliographiques << augment\'es >>. Et les annonces de ces derniers mois, autour des mod\`eles de raisonnement ou de recherche approfondie, augurent de nouveaux changements encore. M\^eme si l'on manque encore de recul sur ces technologies r\'ecentes et \'evolutives, il est d'ores et d\'ej\`a possible d'identifier un certain nombre de points-cl\'es et de questions autour de l'int\'egration de ces nouveaut\'es dans le cadre acad\'emique. \'Etat des lieux et perspectives deux ans apr\`es la sortie de ChatGPT...},
  annotation = {Pinned\_Collections: library}
}

@misc{cabezas-clavijo2025AssessingPerformance,
  title = {Assessing the Performance of 8 {{AI}} Chatbots in Bibliographic Reference Retrieval: {{Grok}} and {{DeepSeek}} Outperform {{ChatGPT}}, but None Are Fully Accurate},
  shorttitle = {Assessing the Performance of 8 {{AI}} Chatbots in Bibliographic Reference Retrieval},
  author = {{Cabezas-Clavijo}, {\'A}lvaro and {Sidorenko-Bautista}, Pavel},
  year = 2025,
  month = may,
  number = {arXiv:2505.18059},
  eprint = {2505.18059},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2505.18059},
  urldate = {2025-07-22},
  abstract = {This study analyzes the performance of eight generative artificial intelligence chatbots -- ChatGPT, Claude, Copilot, DeepSeek, Gemini, Grok, Le Chat, and Perplexity -- in their free versions, in the task of generating academic bibliographic references within the university context. A total of 400 references were evaluated across the five major areas of knowledge (Health, Engineering, Experimental Sciences, Social Sciences, and Humanities), based on a standardized prompt. Each reference was assessed according to five key components (authorship, year, title, source, and location), along with document type, publication age, and error count. The results show that only 26.5\% of the references were fully correct, 33.8\% partially correct, and 39.8\% were either erroneous or entirely fabricated. Grok and DeepSeek stood out as the only chatbots that did not generate false references, while Copilot, Perplexity, and Claude exhibited the highest hallucination rates. Furthermore, the chatbots showed a greater tendency to generate book references over journal articles, although the latter had a significantly higher fabrication rate. A high degree of overlap was also detected among the sources provided by several models, particularly between DeepSeek, Grok, Gemini, and ChatGPT. These findings reveal structural limitations in current AI models, highlight the risks of uncritical use by students, and underscore the need to strengthen information and critical literacy regarding the use of AI tools in higher education.},
  archiveprefix = {arXiv},
  annotation = {Pinned\_Collections: library}
}

@article{camp2025CitationCatastrophe,
  title = {The Citation Catastrophe: {{Propagation}} of {{AI-generated}} Counterfeit Citations in Scholarship},
  shorttitle = {The Citation Catastrophe},
  author = {Camp, Nathan T. and Bengtson, Jason A. and Sandstrom, John C.},
  year = 2025,
  month = jul,
  journal = {The Journal of Academic Librarianship},
  volume = {51},
  number = {4},
  pages = {103065},
  issn = {0099-1333},
  doi = {10.1016/j.acalib.2025.103065},
  urldate = {2025-07-22},
  abstract = {Knowledge creation in the academy is built upon the research of previous scholars. This legacy scholarship is tracked in new papers through the use of citations. Citations of prior work in academic papers create a network of related scholarship that serves as a firm foundation for successive work. However, the authors of this paper document examples of ``counterfeit citations'', almost certainly created by Large Language Models, which represent academic work which does not actually exist. The authors track the propagation of these example counterfeit citations in the literature and discuss the damage they cause, means of measuring comparative value in affected citation databases, and potential remediation of this problem moving forward.},
  annotation = {Pinned\_Collections: library}
}

@article{giray2024ChatGPTReferences,
  title = {{{ChatGPT References Unveiled}}: {{Distinguishing}} the {{Reliable}} from the {{Fake}}},
  shorttitle = {{{ChatGPT References Unveiled}}},
  author = {Giray, Louie},
  year = 2024,
  month = jan,
  journal = {Internet Reference Services Quarterly},
  volume = {28},
  number = {1},
  pages = {9--18},
  publisher = {Routledge},
  issn = {1087-5301},
  doi = {10.1080/10875301.2023.2265369},
  urldate = {2025-07-28},
  abstract = {This study explored the potential of ChatGPT in the search for reliable references. Results showed that the reliability of ChatGPT's references vary across different source types. For journal articles, they were all fabricated and not compliant with APA 7 format. Webpages did not match actual existing sites. However, for books, the generated references correctly corresponded to real, existing ones. In the case of journal websites, the links within the responses were functional. Although this exploration gained interesting insights, researchers are strongly recommended not to depend on ChatGPT for references due to accuracy issues and must undertake manual, scholarly searches.}
}

@misc{hutchins2025EveryReason,
  title = {Every {{Reason Why I Hate AI}} and {{You Should Too}}},
  author = {Hutchins, Marcus},
  year = 2025,
  month = aug,
  journal = {MalwareTech},
  urldate = {2025-08-14},
  abstract = {maybe it's anti-innovation, maybe it's just avoiding hype. But one thing is clear, I'm completely done with hearing about AI.},
  chapter = {Opinions},
  howpublished = {https://malwaretech.com/2025/08/every-reason-why-i-hate-ai.html},
  langid = {english}
}

@article{jensen2025AILiteracy,
  title = {{{AI}} Literacy in the Context of Working with Sources: {{Pitfalls}} and Possibilities of Generative {{AI}} Models in Academic Writing},
  author = {Jensen, Tine Wirenfeldt and Jensen, S{\o}ren Wirenfeldt},
  year = 2025,
  journal = {Journal of Academic Writing},
  volume = {14},
  number = {S2 2025},
  pages = {1--12},
  doi = {10.18552/joaw.v15iS2.1224},
  abstract = {This study examines the integration of generative AI (GenAI), such as ChatGPT, into students' academic writing practices, focusing on its use for finding and working with sources. Using the concept of `imagined affordances' we explore how students perceive and interact with this technology in academic contexts. We tested six student-centric prompting strategies across three fields using ChatGPT 3.5 and 4o, simulating realistic academic writing scenarios. Results show significant variations in the accuracy and usability of generated references across fields, strategies, and model versions. Notably, some strategies based on students' imagined affordances, though technically unsound, produced useful outputs for academic writing tasks. ChatGPT 4o generally outperformed 3.5, highlighting rapid advancements in GenAI's potential role in academic writing. These findings reveal a growing gap between institutional guidance on GenAI use in academic writing and students' potential experiences. We advocate for a nuanced approach to AI literacy in higher education that acknowledges students' perspectives, fosters open dialogue, destigmatizes experimentation while emphasizing critical evaluation, and raises awareness of how imagined affordances shape GenAI interactions during the writing process. This study contributes to discussions on AI integration in academic writing, offering insights for writing instructors, librarians, and policymakers.},
  langid = {english}
}

@article{kousha2024HowChatGPT,
  title = {How Is {{ChatGPT}} Acknowledged in Academic Publications?},
  author = {Kousha, Kayvan},
  year = 2024,
  month = dec,
  journal = {Scientometrics},
  volume = {129},
  number = {12},
  pages = {7959--7969},
  issn = {1588-2861},
  doi = {10.1007/s11192-024-05193-y},
  urldate = {2025-09-13},
  abstract = {This study analysed the acknowledgment of ChatGPT in 1,759 academic publications indexed in Scopus and Web of Science up to August 2024. Around 80\% of acknowledgments were related to text editing and proofreading, while only 5.3\% mentioned ChatGPT for non-editorial research support, such as data analysis or programming. A small portion (3.5\%) of researchers acknowledged ChatGPT for drafting sections of manuscripts. About two-thirds of corresponding authors who acknowledged ChatGPT were from non-English-speaking countries, and 75\% of the publications with ChatGPT acknowledgments were published within January to August 2024. These findings suggest that ChatGPT was primarily acknowledged for language enhancement rather than more complex research applications, although some researchers may not have found it necessary to mention its use in their publications, highlighting the need for transparency from journals and publishers.},
  langid = {english}
}

@article{lenharo2024ChatGPTTurns,
  title = {{{ChatGPT}} Turns Two: How the {{AI}} Chatbot Has Changed Scientists' Lives},
  shorttitle = {{{ChatGPT}} Turns Two},
  author = {Lenharo, Mariana},
  year = 2024,
  month = dec,
  journal = {Nature},
  volume = {636},
  number = {8042},
  pages = {281--282},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/d41586-024-03940-y},
  urldate = {2025-07-09},
  abstract = {How many researchers are using the AI tool? Nature gathers data and talks to members of the academic community.},
  copyright = {2024 Springer Nature Limited},
  langid = {english},
  annotation = {Bandiera\_abtest: a\\
Cg\_type: News\\
Subject\_term: Computer science, Scientific community, Machine learning\\
Pinned\_Collections: library}
}

@article{lund2023ChatGPTNew,
  title = {{{ChatGPT}} and a New Academic Reality: {{Artificial Intelligence-written}} Research Papers and the Ethics of the Large Language Models in Scholarly Publishing},
  shorttitle = {{{ChatGPT}} and a New Academic Reality},
  author = {Lund, Brady D. and Wang, Ting and Mannuru, Nishith Reddy and Nie, Bing and Shimray, Somipam and Wang, Ziang},
  year = 2023,
  journal = {Journal of the Association for Information Science and Technology},
  volume = {74},
  number = {5},
  pages = {570--581},
  issn = {2330-1643},
  doi = {10.1002/asi.24750},
  urldate = {2025-07-09},
  abstract = {This article discusses OpenAI's ChatGPT, a generative pre-trained transformer, which uses natural language processing to fulfill text-based user requests (i.e., a ``chatbot''). The history and principles behind ChatGPT and similar models are discussed. This technology is then discussed in relation to its potential impact on academia and scholarly research and publishing. ChatGPT is seen as a potential model for the automated preparation of essays and other types of scholarly manuscripts. Potential ethical issues that could arise with the emergence of large language models like GPT-3, the underlying technology behind ChatGPT, and its usage by academics and researchers, are discussed and situated within the context of broader advancements in artificial intelligence, machine learning, and natural language processing for research and scholarly publishing.},
  copyright = {\copyright{} 2023 Association for Information Science and Technology.},
  langid = {english},
  annotation = {Pinned\_Collections: library}
}

@misc{maraninchi2025PourquoiJe,
  title = {{Pourquoi je n'utilise pas ChatGPT}},
  author = {Maraninchi, Florence},
  year = 2025,
  month = feb,
  journal = {Academia},
  issn = {2265-2434},
  doi = {10.58079/1382x},
  urldate = {2025-02-05},
  abstract = {Par Florence Maraninchi L'ann\'ee 2025 est d\'ej\`a particuli\`erement f\'econde en nouvelles plus fracassantes les unes que les autres sur les financements, la course aux armements entre la Chine et les USA, le sommet intergalactique sur l'IA \`a Paris, et les \dots{} Continuer la lecture {$\rightarrow$}},
  langid = {french}
}

@misc{mekhfi2024UtiliserIA,
  title = {{Utiliser les IA g\'en\'eratrices pour Zotero}},
  author = {Mekhfi, Ikram},
  year = 2024,
  month = apr,
  journal = {Arch\'eO'liens},
  issn = {3000-8506},
  doi = {10.58079/11pj3},
  urldate = {2025-07-07},
  abstract = {ChatGPT est un mod\`ele de langage conversationnel diffus\'e en novembre 2022 par OpenAI. (voir l'article On a test\'e pour vous...},
  langid = {french}
}

@article{messeri2024ArtificialIntelligence,
  title = {Artificial Intelligence and Illusions of Understanding in Scientific Research},
  author = {Messeri, Lisa and Crockett, M. J.},
  year = 2024,
  month = mar,
  journal = {Nature},
  volume = {627},
  number = {8002},
  pages = {49--58},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/s41586-024-07146-0},
  urldate = {2025-08-05},
  abstract = {Scientists are enthusiastically imagining ways in which artificial intelligence (AI) tools might improve research. Why are AI tools so attractive and what are the risks of implementing them across the research pipeline? Here we develop a taxonomy of scientists' visions for AI, observing that their appeal comes from promises to improve productivity and objectivity by overcoming human shortcomings. But proposed AI solutions can also exploit our cognitive limitations, making us vulnerable to illusions of understanding in which we believe we understand more about the world than we actually do. Such illusions obscure the scientific community's ability to see the formation of scientific monocultures, in which some types of methods, questions and viewpoints come to dominate alternative approaches, making science less innovative and more vulnerable to errors. The proliferation of AI tools in science risks introducing a phase of scientific enquiry in which we produce more but understand less. By analysing the appeal of these tools, we provide a framework for advancing discussions of responsible knowledge production in the age of AI.},
  copyright = {2024 Springer Nature Limited},
  langid = {english}
}

@book{miao2024OrientationsPour,
  title = {Orientations Pour l'intelligence Artificielle G\'en\'erative Dans l'\'education et La Recherche},
  author = {Miao, Fengchun and Holmes, Wayne},
  year = 2024,
  publisher = {'Organisation des Nations Unies pour l'\'education, la science et la culture},
  doi = {10.54675/HBCX3851},
  urldate = {2025-09-22},
  isbn = {978-92-3-200312-6},
  annotation = {Pinned\_Collections: library}
}

@article{oladokun2025HallucitationScientific,
  title = {Hallucitation in {{Scientific Writing}}: {{Exploring Evidence}} from {{ChatGPT Versions}} 3.5 and 4o in {{Responses}} to {{Selected Questions}} in {{Librarianship}}},
  shorttitle = {Hallucitation in {{Scientific Writing}}},
  author = {Oladokun, Bolaji David and Enakrire, Rexwhite Tega and Emmanuel, Adefila Kolawole and Ajani, Yusuf Ayodeji and Adetayo, Adebowale Jeremy},
  year = 2025,
  month = jan,
  journal = {Journal of Web Librarianship},
  volume = {19},
  number = {1},
  pages = {62--92},
  publisher = {Routledge},
  issn = {1932-2909},
  doi = {10.1080/19322909.2025.2482093},
  urldate = {2025-07-22},
  abstract = {The rapid adoption of AI in academic writing, particularly with tools like ChatGPT, has raised significant concerns regarding the accuracy of generated content. This study explores the phenomenon of ``hallucitation'' in scientific writing, where AI models fabricate citations, analyzing responses from ChatGPT versions 3.5 and 4o in the context of librarianship. Through an experimental design, scientific content with citations was generated and systematically verified using Google Scholar and the publisher's website. The findings reveal a disturbingly high frequency of false or non-existent citations---42.9\% in ChatGPT-3.5 and 51.8\% in ChatGPT-4o. Despite slight improvements in citation accuracy from version 3.5 to 4o, with accuracy rates of 3.92\% and 6.35\%, respectively, both versions exhibit significant limitations. Notably, ChatGPT 3.5 frequently generated completely fabricated sources, while ChatGPT-4o introduced subtle errors, such as mismatched journals. The study indicates no significant difference in accuracy between the two versions, underscoring the persistent risks associated with AI-generated citations. These findings highlight the urgent need for rigorous verification of AI-generated content to safeguard the integrity of scholarly work.},
  annotation = {Pinned\_Collections: library}
}

@article{orduna-malea2023ChatGPTPotential,
  title = {{{ChatGPT}} and the Potential Growing of Ghost Bibliographic References},
  author = {{Ordu{\~n}a-Malea}, Enrique and {Cabezas-Clavijo}, {\'A}lvaro},
  year = 2023,
  month = sep,
  journal = {Scientometrics},
  volume = {128},
  number = {9},
  pages = {5351--5355},
  issn = {0138-9130, 1588-2861},
  doi = {10.1007/s11192-023-04804-4},
  urldate = {2023-08-22},
  langid = {english},
  annotation = {10 citations (Crossref/DOI) [2024-09-11]\\
Pinned\_Collections: library}
}

@techreport{pascal2025IAEnseignement,
  title = {{IA et enseignement sup\'erieur : formation, structuration et appropriation}},
  author = {Pascal, Fr{\'e}d{\'e}ric and Taddei, Fran{\c c}ois},
  year = 2025,
  month = jun,
  institution = {Minist\`ere de l'enseignement sup\'erieur et de la recherche},
  urldate = {2025-12-06},
  abstract = {\textbar{} Ce rapport s'inscrit dans le cadre d'une mission sur "l'intelligence artificielle dans les pratiques p\'edagogiques". Cette mission vise \`a analyser les impacts potentiels de l'intelligence artificielle (IA) sur les pratiques p\'edagogiques, administratives et organisationnelles dans le monde acad\'emique.Le rapport souligne que les \'etablissements d'enseignement sup\'erieur doivent se transformer pour devenir de v\'eritables catalyseurs de changement au sein d'une soci\'et\'e apprenante et propose six grandes actions prioritaires :Former les formateurs et les \'etudiants,Adopter l'IA dans les \'etablissements d'enseignement sup\'erieur et dans la soci\'et\'e,Transformer l'universit\'e \`a l'heure de l'IA,D\'evelopper les infrastructures et les solutions techniques,Mutualiser les contenus et les bonnes pratiques,Porter une politique nationale de l'adoption de l'IA dans l'\'education.},
  langid = {french}
}

@misc{rempel2025GenerativeAI,
  title = {Generative {{AI Tools}} for {{Literature Reviews}}},
  shorttitle = {{{LibGuides}}},
  author = {Rempel, Hannah},
  year = 2025,
  month = feb,
  journal = {LibGuides at Oregon State University},
  urldate = {2025-02-11},
  abstract = {LibGuides: Generative AI Tools for Literature Reviews: Comparison of AI Literature Review Tools},
  copyright = {Copyright Oregon State University 2025},
  howpublished = {https://guides.library.oregonstate.edu/c.php?g=1421175\&p=10536219},
  langid = {english}
}

@article{resnik2025EthicsUsing,
  title = {The Ethics of Using Artificial Intelligence in Scientific Research: New Guidance Needed for a New Tool},
  shorttitle = {The Ethics of Using Artificial Intelligence in Scientific Research},
  author = {Resnik, David B. and Hosseini, Mohammad},
  year = 2025,
  month = apr,
  journal = {AI and Ethics},
  volume = {5},
  number = {2},
  pages = {1499--1521},
  issn = {2730-5961},
  doi = {10.1007/s43681-024-00493-8},
  urldate = {2025-07-09},
  abstract = {Using artificial intelligence (AI) in research offers many important benefits for science and society but also creates novel and complex ethical issues. While these ethical issues do not necessitate changing established ethical norms of science, they require the scientific community to develop new guidance for the appropriate use of AI. In this article, we briefly introduce AI and explain how it can be used in research, examine some of the ethical issues raised when using it, and offer nine recommendations for responsible use, including: (1) Researchers are responsible for identifying, describing, reducing, and controlling AI-related biases and random errors; (2) Researchers should disclose, describe, and explain their use of AI in research, including its limitations, in language that can be understood by non-experts; (3) Researchers should engage with impacted communities, populations, and other stakeholders concerning the use of AI in research to obtain their advice and assistance and address their interests and concerns, such as issues related to bias; (4) Researchers who use synthetic data should (a) indicate which parts of the data are synthetic; (b) clearly label the synthetic data; (c) describe how the data were generated; and (d) explain how and why the data were used; (5) AI systems should not be named as authors, inventors, or copyright holders but their contributions to research should be disclosed and described; (6) Education and mentoring in responsible conduct of research should include discussion of ethical use of AI.},
  langid = {english},
  annotation = {Pinned\_Collections: library}
}

@misc{schlafer2023ImporterReferences,
  title = {{Importer des r\'ef\'erences bibliographiques non-format\'ees dans zotero avec anystyle ou avec l'aide de ChatGPT}},
  author = {Schl{\"a}fer, Annette},
  year = 2023,
  month = aug,
  journal = {Germano-Fil},
  issn = {2257-6428},
  doi = {10.58079/p0zy},
  urldate = {2025-07-09},
  abstract = {<<~J'ai toute ma bibliographie dans un document word. Est-ce qu'il y a un moyen pour l'importer automatiquement dans zotero~?~>> C'est une des questions pr\'ef\'er\'ees des participants et participantes \`a nos formations de recherche documentaire...},
  langid = {french}
}

@article{spennemann2025OriginsVeracity,
  title = {The {{Origins}} and {{Veracity}} of {{References}} `{{Cited}}' by {{Generative Artificial Intelligence Applications}}: {{Implications}} for the {{Quality}} of {{Responses}}},
  shorttitle = {The {{Origins}} and {{Veracity}} of {{References}} `{{Cited}}' by {{Generative Artificial Intelligence Applications}}},
  author = {Spennemann, Dirk H. R.},
  year = 2025,
  month = mar,
  journal = {Publications},
  volume = {13},
  number = {1},
  pages = {12},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2304-6775},
  doi = {10.3390/publications13010012},
  urldate = {2025-07-28},
  abstract = {The public release of ChatGPT in late 2022 has resulted in considerable publicity and has led to widespread discussion of the usefulness and capabilities of generative Artificial intelligence (Ai) language models. Its ability to extract and summarise data from textual sources and present them as human-like contextual responses makes it an eminently suitable tool to answer questions users might ask. Expanding on a previous analysis of the capabilities of ChatGPT3.5, this paper tested what archaeological literature appears to have been included in the training phase of three recent generative Ai language models: ChatGPT4o, ScholarGPT, and DeepSeek R1. While ChatGPT3.5 offered seemingly pertinent references, a large percentage proved to be fictitious. While the more recent model ScholarGPT, which is purportedly tailored towards academic needs, performed much better, it still offered a high rate of fictitious references compared to the general models ChatGPT4o and DeepSeek. Using `cloze' analysis to make inferences on the sources `memorized' by a generative Ai model, this paper was unable to prove that any of the four genAi models had perused the full texts of the genuine references. It can be shown that all references provided by ChatGPT and other OpenAi models, as well as DeepSeek, that were found to be genuine, have also been cited on Wikipedia pages. This strongly indicates that the source base for at least some, if not most, of the data is found in those pages and thus represents, at best, third-hand source material. This has significant implications in relation to the quality of the data available to generative Ai models to shape their answers. The implications of this are discussed.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  annotation = {Pinned\_Collections: library}
}

@misc{tay20252025Deep,
  title = {A 2025 {{Deep Dive}} of {{Consensus}}: {{Promises}} and {{Pitfalls}} in {{AI-Powered Academic Search}}},
  shorttitle = {A 2025 {{Deep Dive}} of {{Consensus}}},
  author = {Tay, Aaron},
  year = 2025,
  month = nov,
  journal = {Aaron Tay's Musings about Librarianship},
  urldate = {2026-01-31},
  abstract = {The recent addition of Consensus Deep Search mode is a great boost to its retrieval capabilities.~On top of that, it has one of the most appealing interfaces out there, with color-coded references, and the Consensus Meter, for all its methodological faults, is likely to appeal to undergraduates and less advanced users. Add advanced pre-filters and LibKey integration to institutional full-text, and it is easy to guess this will be a hit for many users doing narrative literature reviews.}
}

@article{walters2023FabricationErrors,
  title = {Fabrication and Errors in the Bibliographic Citations Generated by {{ChatGPT}}},
  author = {Walters, William H. and Wilder, Esther Isabelle},
  year = 2023,
  month = sep,
  journal = {Scientific Reports},
  volume = {13},
  number = {1},
  pages = {14045},
  publisher = {Nature Publishing Group},
  issn = {2045-2322},
  doi = {10.1038/s41598-023-41032-5},
  urldate = {2025-07-21},
  abstract = {Although chatbots such as ChatGPT can facilitate cost-effective text generation and editing, factually incorrect responses (hallucinations) limit their utility. This study evaluates one particular type of hallucination: fabricated bibliographic citations that do not represent actual scholarly works. We used ChatGPT-3.5 and ChatGPT-4 to produce short literature reviews on 42 multidisciplinary topics, compiling data on the 636 bibliographic citations (references) found in the 84 papers. We then searched multiple databases and websites to determine the prevalence of fabricated citations, to identify errors in the citations to non-fabricated papers, and to evaluate adherence to APA citation format. Within this set of documents, 55\% of the GPT-3.5 citations but just 18\% of the GPT-4 citations are fabricated. Likewise, 43\% of the real (non-fabricated) GPT-3.5 citations but just 24\% of the real GPT-4 citations include substantive citation errors. Although GPT-4 is a major improvement over GPT-3.5, problems remain.},
  copyright = {2023 The Author(s)},
  langid = {english},
  annotation = {Pinned\_Collections: library}
}

@misc{zhao2025EmergingAI,
  title = {Emerging {{AI Tools}} for {{Literature Review}}},
  shorttitle = {{{LibGuides}}},
  author = {Zhao, Aster},
  year = 2025,
  urldate = {2025-07-30},
  abstract = {This guide consolidates the teaching materials for library workshop Emerging AI Tools for Literature Review.},
  copyright = {Copyright Hong Kong University of Science and Technology Library 2025},
  langid = {english},
  annotation = {Pinned\_Collections: library}
}
